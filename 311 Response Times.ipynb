{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read complete:  1917212 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def read_sample_from(fname, n=1000):\n",
    "    with open(fname,'r') as f:\n",
    "        f_len = sum(1 for line in f) - 1\n",
    "        \n",
    "    skip = sorted(random.sample(range(1,f_len),f_len-n))\n",
    "    \n",
    "    return pd.read_csv(\n",
    "        fname, \n",
    "        low_memory=False, usecols=range(27),\n",
    "        skiprows=skip\n",
    "    )\n",
    "\n",
    "# df = read_sample_from('./data/311_Service_Requests_from_2011.csv', 10000)\n",
    "df = pd.read_csv('./data/311_Service_Requests_from_2011.csv',  low_memory=False, usecols=range(27) )\n",
    "print(\"File read complete: \", len(df), 'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training observations:  1328493\n",
      "Number of features:  1053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "df.columns = ['Unique Key', 'Created Date', 'Closed Date', 'Agency', 'Agency Name',\n",
    "       'Complaint Type', 'Descriptor', 'Location Type', 'Incident Zip',\n",
    "       'Incident Address', 'Street Name', 'Cross Street 1', 'Cross Street 2',\n",
    "       'Intersection Street 1', 'Intersection Street 2', 'Address Type',\n",
    "       'City', 'Landmark', 'Facility Type', 'Status', 'Due Date',\n",
    "       'Resolution Description', 'Resolution Action Updated Date',\n",
    "       'Community Board', 'Borough', 'X', 'Y']\n",
    "\n",
    "A = df[df.Status == 'Closed']\n",
    "A = A[A['Closed Date'].notnull()]\n",
    "A.fillna(0, inplace=True)\n",
    "A['Closed Date'] = pd.to_datetime(A['Closed Date'], format='%m/%d/%Y %H:%M:%S %p')\n",
    "A['Created Date'] = pd.to_datetime(A['Created Date'], format='%m/%d/%Y %H:%M:%S %p')\n",
    "A['Created Month'] = A['Created Date'].apply( lambda x: x.month)\n",
    "\n",
    "A['Response Time'] = (A['Closed Date'] - A['Created Date']) / np.timedelta64(1, 'h')\n",
    "\n",
    "A = A[['Agency', 'Complaint Type', 'Location Type', \n",
    "       'City', 'Borough', 'Facility Type', 'Created Month', 'X', 'Y', 'Response Time']]\n",
    "\n",
    "for col in A.columns:\n",
    "    if A[col].dtype not in ['float64', 'int', 'int64']:\n",
    "        dummies = pd.get_dummies(A[col])\n",
    "        A[dummies.columns] = dummies\n",
    "\n",
    "A = A[A['Response Time'] != 0]\n",
    "A = A[A.columns[8:]]\n",
    "\n",
    "train, test = train_test_split(A,test_size=0.2)\n",
    "print(\"Number of training observations: \", len(train))\n",
    "print(\"Number of features: \", len(train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost time\n",
    "\n",
    "First, we tune the model using GridSearch\n",
    "```python\n",
    "import xgboost as xgb\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 100, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'reg:linear'}\n",
    "\n",
    "gbm = GridSearchCV(xgb.XGBRegressor(**ind_params), cv_params, scoring = 'r2', cv=5)\n",
    "optimized_gbm = gbm.fit( train[train.columns[:-1]].values,  train['Response Time'].values)\n",
    "print(optimized_gbm.grid_scores_)\n",
    "```\n",
    "\n",
    "From this, we find that the optimal depth is 3, and child_weight is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "gbm = xgb.XGBRegressor(learning_rate=0.05, n_estimators=100, max_depth=3, min_child_weight=3)\n",
    "gbm.fit( train[train.columns[:-1]].values,  train['Response Time'].values)\n",
    "gbm.score(test[test.columns[:-1]].values, test['Response Time'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
